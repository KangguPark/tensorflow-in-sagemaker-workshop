{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 2] Monitor and Analyze Training Jobs Using Metrics\n",
    "\n",
    "Amazon SageMaker 학습 작업은 모델이 학습 데이터셋에서 샘플들을 제시하여 예측하도록 가르치는 반복적인 프로세스입니다.\n",
    "일반적으로 학습 알고리즘은 학습 오차(training error) 및 예측 정확도(prediction accuracy)와 같은 여러 지표들(metrics)을 계산합니다. 이러한 지표들은 모델이 잘 학습되고 있는지 확인하고 신규 데이터를 잘 예측할 수 있도록 일반화합니다.\n",
    "\n",
    "학습 알고리즘은 이러한 지표들의 값을 Amazon SageMaker가 모니터링하고 실시간으로 Amazon CloudWatch로 전송하는 로그에 기록합니다.\n",
    "\n",
    "Amazon SageMaker가 사용자 정의 알고리즘의 로그를 파싱하고 알고리즘이 생성하는 지표를 CloudWatch로 보내려면, 학습 작업을 설정할 때 Amazon SageMaker가 CloudWatch로 전송할 지표를 지정해야 합니다.<br>\n",
    "이 때, 여러분은 전송하려는 지표들의 이름과 정규표현식들(regular expressions)을 지정해야 합니다. 정규표현식들은 Amazon SageMaker가 해당 지표를 찾기 위해 필요합니다.\n",
    "\n",
    "본 실습에서는 Amazon SageMaker를 활용한 지표 모니터링에 대해 실시합니다. 실습 전반에서는 Amazon CloudWatch를 사용하여 모니터링을 실시합니다.\n",
    "실습 후반에서는 Keras에서 출력하는 학습 로그를 활용하여 TensorBoard에서 학습 상황을 모니터링해 봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Training Metrics (Amazon SageMaker Python SDK)\n",
    "\n",
    "Estimator 객체를 초기화할 때 지표 이름 및 정규식 목록을 metric_definitions 인수로 지정하여 CloudWatch로 보내려는 지표를 정의하세요. 예를 들어 CloudWatch에서 train:error 및 validation:error 지표를 모두 모니터링하려는 경우 Estimator 초기화 방법은 다음 코드와 같습니다.\n",
    "\n",
    "```python \n",
    "estimator = Estimator(image_name=ImageName,\n",
    "            role='SageMakerRole', train_instance_count=1,\n",
    "            train_instance_type='ml.c4.xlarge',            \n",
    "            k=10,\n",
    "            metric_definitions=[\n",
    "                   {'Name': 'train:error', 'Regex': 'Train_error=(.*?);'},\n",
    "                   {'Name': 'validation:error', 'Regex': 'Valid_error=(.*?);'}\n",
    "            ])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring the CIFAR10 training\n",
    "아래 작업들을 직접 수행해 보세요.\n",
    "- SageMaker 콘솔에서 이전에 학습했던 학습 작업(cifar10_keras_sm)을 찾아 보세요.\n",
    "- 작업 세부 사항(job details)을 열고 CloudWatch 로그를 확인합니다.\n",
    "- 로그에 맞는 지표 정규식을 설정하세요. 정규식 도구들(regex tools)을 사용하여 정규식을 확인하고 ()를 사용하여 각 matric을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {'Name': 'train:loss', 'Regex': 'loss: (.*?) '},\n",
    "    {'Name': 'train:accuracy', 'Regex': 'acc: (.*?) '},\n",
    "    {'Name': 'validation:loss', 'Regex': 'val_loss: (.*?) '},\n",
    "    {'Name': 'validation:accuracy', 'Regex': 'val_acc: (.*?) '}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'data/DEMO-cifar10'\n",
    "dataset_location = os.path.join('s3://', sagemaker_session.default_bucket(), prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`0_Running_TensorFlow_In_SageMaker.ipynb`의 estimator 인스턴스 생성 코드를 그대로 복사 후에\n",
    "`metric_definitions=metric_definitions` 인자를 추가해 주세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "estimator = TensorFlow(base_job_name='cifar10-cloudwatch',\n",
    "                       entry_point='cifar10_keras_sm.py',\n",
    "                       source_dir='training_script',\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True,                       \n",
    "                       hyperparameters={'epochs': 5},\n",
    "                       train_instance_count=1,\n",
    "                       train_instance_type='ml.p2.xlarge',\n",
    "                       metric_definitions=metric_definitions) # 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "estimator.fit({'train':'{}/train'.format(dataset_location),\n",
    "              'validation':'{}/validation'.format(dataset_location),\n",
    "              'eval':'{}/eval'.format(dataset_location)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the job training metrics\n",
    "SageMaker는 위에서 구성한 정규식을 사용하여 작업 지표(job metrics)를 CloudWatch 지표로 전송했습니다.\n",
    "이제 SageMaker 콘솔에서 직접 작업 지표을 보실 수 있습니다.\n",
    "\n",
    "[SageMaker console](https://console.aws.amazon.com/sagemaker/home) 에 로그인하여 최신 학습 작업(latest training job)을 선택하고 모니터 섹션(monitor section)까지 아래로 스크롤하십시오.\n",
    "CloudWatch 지표를 사용하여 기간(period)을 변경하고 통계치(statistics)들을 설정할 수 있습니다\n",
    "\n",
    "다음 셀(cell)을 사용하여 지표를 찾아 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Markdown\n",
    "\n",
    "link = 'https://console.aws.amazon.com/cloudwatch/home?region='+sagemaker_session.boto_region_name+'#metricsV2:query=%7B/aws/sagemaker/TrainingJobs,TrainingJobName%7D%20'+estimator.latest_training_job.job_name\n",
    "display(Markdown('CloudWatch metrics: [link]('+link+')'))\n",
    "display(Markdown('After you choose a metric, change the period to 1 Minute (Graphed Metrics -> Period)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('CloudWatch metrics: [link]('+link+')'))\n",
    "display(Markdown('After you choose a metric, change the period to 1 Minute (Graphed Metrics -> Period)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor with TensorBoard\n",
    "\n",
    "이번에는 TensorBoard로 학습 작업을 실시간으로 모니터링해 봅니다.<br>\n",
    "TensorBoard는 머신 러닝 실험에 필요한 시각화 및 도구들을 제공합니다.\n",
    "* Loss 및 accuracy과 같은 metric 추적 및 시각화\n",
    "* 모델 그래프 (ops 및 layers) 시각화\n",
    "* 시간 경에 따라 변화하는 가중치(weights), 바이어스(biases) 또는 기타 텐서의 히스토그램 확인\n",
    "* 저차원 공간으로 임베딩(embedding)\n",
    "* 이미지, 텍스트 및 오디오 데이터 표시\n",
    "* 기타 \n",
    "\n",
    "**`training_script/cifar10_keras_sm.py`에서 스크립트 사본을 생성 후, `training_script/cifar10_keras_tensorboard.py`로 저장하세요.**\n",
    "\n",
    "스크립트 사본을 생성하였다면 단계별로 아래의 작업들을 직접 시도합니다.\n",
    "\n",
    "----\n",
    "### TODO 1.\n",
    "\n",
    "먼저, 학습 로그를 TensorBoard로 전송하기 위해 `cifar10_keras_tensorboard.py` 스크립트를 수정합니다.<br>\n",
    "Keras에서 TensorBoard를 사용하려면 코드 상단에 `from keras.callbacks import TensorBoard` 구문을 추가해 주세요.\n",
    "\n",
    "Keras는 디폴트로 각 배치(batch)마다 TensorBoard 로그를 보냅니다. S3에 로그를 전송하면 학습 작업이 느려지기 때문에,\n",
    "TensorBoard callback을 각 epoch의 끝에서만 로그를 전송할 수 있게 변경해 주는 것이 좋습니다.\n",
    "\n",
    "----\n",
    "### TODO 2.\n",
    "\n",
    "스크립트에 TensorBoard callback을 추가해 주세요 (ModelCheckpoint callback 바로 다음 라인에 아래 줄을 추가해 주세요).\n",
    "```python\n",
    "callbacks.append(TensorBoard(log_dir=args.model_output_dir,update_freq='epoch'))\n",
    "```\n",
    "\n",
    "<font color='blue'>**본 노트북 실습에 어려움이 있다면 솔루션 파일 `training_script/cifar10_keras_tensorboard_solution.py`을 참조하시면 됩니다.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a training job with TensorBoard support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "estimator = TensorFlow(base_job_name='cifar10-tensorboard',\n",
    "#                       entry_point='cifar10_keras_tensorboard.py',\n",
    "                       entry_point='cifar10_keras_tensorboard.py',                       \n",
    "                       source_dir='training_script',\n",
    "                       role=role,\n",
    "                       framework_version='1.12.0',\n",
    "                       py_version='py3',\n",
    "                       hyperparameters={'epochs' : 5},\n",
    "                       train_instance_count=1,\n",
    "                       train_instance_type='ml.p2.xlarge',\n",
    "                       metric_definitions=metric_definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'train':'{}/train'.format(dataset_location),\n",
    "              'validation':'{}/validation'.format(dataset_location),\n",
    "#              'eval':'{}/eval'.format(dataset_location)}, wait=False)\n",
    "              'eval':'{}/eval'.format(dataset_location)}, wait=True)\n",
    " # Use wait=False to run async jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Tensorboard on your local machine\n",
    "\n",
    "`pip install tensorboard`를 사용하여 [TensorBoard](https://github.com/tensorflow/tensorboard)를 로컬에 설치해 주세요.\n",
    "S3 로그 디렉토리에 접근하기 위해 TensorBoard 기본 리젼을 설정해 주세요. 여러분은 `AWS_REGION`이라는 환경 변수를 설정하고 환경 변수의 값을 학습 작업이 실행되는 AWS 리전으로 설정하면 됩니다.\n",
    "예를 들면 `AWS_REGION='us-east-2' tensorboard --logdir model_dir` 입니다.\n",
    "\n",
    "**여러분은 다음 셀(cell)에서 TensorBoard command를 얻을 수 있습니다.**\n",
    "\n",
    "여러분은 model_dir(S3 위치)에 접근 하기 위해서는 AccessKey + SecretKey 가 필요 합니다. \n",
    "이벤트 엔진을 사용하시는 분은 아래에서 얻을 수 있습니다. AccessKey + SecretKey 를 프로프트 창에 실행 시키시고 아래의 가이드에 따라 진행 해주세요,  <br>\n",
    "https://dashboard.eventengine.run/dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Markdown\n",
    "\n",
    "link = 'AWS_REGION=\\''+sagemaker_session.boto_region_name+'\\' tensorboard --logdir ' + estimator.model_dir + ' --host localhost --port 6006'\n",
    "display(Markdown('본 셀의 output(Tensorboard command) 기억 해주세요.'))\n",
    "display(Markdown(link))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**이후에 다음 순서와 같이 진행 해 주세요.**\n",
    "* AWS Console에서 S3 서비스로 이동 합니다.\n",
    "* 위의 결과 S3 위치를 보면서 (예: s3://sagemaker-us-east-2-057716757052/cifar10-tensorboard-2020-03-01-09-59-29-896) 버킷과 폴더를 확인 하세요.<br>\n",
    "(s3://<버킷 이름>/<폴더 이름>)\n",
    "* 버킷 --> 폴더 까지 이동 하신 후에 model 폴더를 생성 하세요.\n",
    "* 버킷 --> 폴더 --> output --> model.tar.gz 파일을 로컬에 다운로드 하세요.\n",
    "* 로컬에서 model.tar.gz를 압추 해제를 하면 event.out.tfevents.* 파일이 있습니다. <br>\n",
    "(예: events.out.tfevents.1583057000.ip-10-0-136-231.us-east-2.compute.internal)<br>\n",
    "이 파일을 전에 생성한 버킷 --> 폴더 --> model 안에 업로드 해주세요.\n",
    "* 위 셀의 결과인 Tensorboard command 을 (예: AWS_REGION='us-east-2' tensorboard --logdir s3://sagemaker-us-east-2-057716757052/cifar10-tensorboard-2020-03-01-09-59-29-896/model --host localhost --port 6006) 로컬의 프로프트 창에 넣어 실행 해주세요.\n",
    "* 이후에 브라우저(예:크롬) 에서 localhost:6006 을 주소창에 넣고 실행 해주시면 됩니다.\n",
    "* 아래와 같이 tensorboard 가 보이실 겁니다.<br>\n",
    "![tensorboard](./images/tensorboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**잘 하셨습니다.**\n",
    "\n",
    "이제 여러분의 학습 작업을 CloudWatch 지표와 TensorBoard로 확인할 수 있습니다.<br>\n",
    "다음 노트북으로 계속 진행하기 전에 다른 TensorBoard 설정값들을 [TensorBoard callback configuration](https://keras.io/callbacks/#tensorboard)에서 살펴보세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
